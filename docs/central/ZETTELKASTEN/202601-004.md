# 202601-004: Prompt Caching — 90% oszczędności na powtarzalnych kontekstach

**confidence:** 0.95
**source:** https://platform.claude.com/docs/en/build-with-claude/prompt-caching
**version:** 1
**deprecated:** false
**superseded_by:** []
**tags:** [@_jarvis, @claude-api, @optymalizacja, @koszty]

## Fakt

Prompt caching pozwala oznaczyć statyczną zawartość (system prompts, instrukcje, baza wiedzy) jako cacheowalną. Kolejne requesty czytają z cache za 10% ceny.

Parametry:
- Cache write: $3.75/MTok (1.25x cena bazowa)
- Cache read: $0.30/MTok (0.1x cena bazowa)
- TTL: 5 minut (ephemeral)
- ROI: po ~13 requestach cache zwraca koszt

Implementacja:
```python
system=[{
    "type": "text",
    "text": open("CLAUDE_RULES.md").read(),
    "cache_control": {"type": "ephemeral"}
}]
```

## Kontekst

Dla Jarvisa — cache CLAUDE_RULES.md, GIT_STRATEGY.md, STYLE_GUIDE.md, KNOWLEDGE.md. Przy 100+ requestów/dzień = znacząca oszczędność.

## Powiązania

- → 202601-002: Tool Runner + caching = optymalna kombinacja
- → 202601-005: W L2+ cache na pamięć długoterminową (MEMORY.md)

## Źródło surowe

> "Prompt caching allows you to cache the prefix of your prompts, reducing costs by up to 90% for repeated content."
